{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbdec9e-0dc5-4b40-8c8e-49496bb75c4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Limpeza e Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce488750-d02f-45ca-89be-01a45f5063e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregando o dataframe\n",
    "df = pd.read_csv('<caminho_dados>.csv', sep=',', low_memory=False)\n",
    "\n",
    "# Criando uma nova coluna 'co_turma' composta por 'co_entidade' e 'co_etapa_ensino'\n",
    "# Esse código deve aparecer uma vez a cada ano que a turma foi registrada no censo escolar\n",
    "df['co_turma'] = df['co_entidade'].astype(str) + '-' + df['co_etapa_ensino'].astype(str)\n",
    "\n",
    "# Levantando o código das turmas que aparecem no censo de 2023\n",
    "turmas_com_2023 = df[df['nu_ano_censo'] == 2023]['co_turma']\n",
    "\n",
    "# Filtrando o dataframe apenas pelas turmas que aparecem no censo de 2023\n",
    "df_filtrado_2023 = df[df['co_turma'].isin(turmas_com_2023)]\n",
    "\n",
    "# Agrupando por turma e adicionando a quantidade de registros\n",
    "df_filtrado_2023_agrupado = df_filtrado_2023.groupby(['co_turma']).size().reset_index(name='quantitativo')\n",
    "df_filtrado_2023_agrupado = df_filtrado_2023_agrupado.sort_values(by='quantitativo', ascending=False)\n",
    "\n",
    "# Removendo linhas onde o quantitativo de registros é menor que 10 e pegando o código das turmas\n",
    "df_filtrado_2023_agrupado_maior_igual_10 = df_filtrado_2023_agrupado[df_filtrado_2023_agrupado['quantitativo'] >= 10]\n",
    "turmas_2023_maior_igual_10 = df_filtrado_2023_agrupado_maior_igual_10['co_turma'].unique()\n",
    "\n",
    "# Filtrando o dataframe apenas pelas turmas que aparecem no censo de 2023 e tem 10 ou mais registros\n",
    "df_filtrado_2023_maior_igual_10 = df[df['co_turma'].isin(turmas_2023_maior_igual_10)]\n",
    "\n",
    "# Copiando o df e convertendo os valores de ano para string para poder usar como nome de coluna\n",
    "df_filtrado_2023_maior_igual_10_copia = df_filtrado_2023_maior_igual_10.copy()\n",
    "df_filtrado_2023_maior_igual_10_copia['nu_ano_censo'] = df_filtrado_2023_maior_igual_10_copia['nu_ano_censo'].astype(str)\n",
    "\n",
    "# Usando pivot_table para montar o df da série temporal\n",
    "# Os valores de 'qtd_alunos' serão distribuídos conforme 'nu_ano_censo', para cada 'co_turma'\n",
    "# Valores NaN serão preenchidos com 0 e o name do index será removido\n",
    "df_serie_temporal = df_filtrado_2023_maior_igual_10_copia.pivot_table(\n",
    "        index='co_turma',columns='nu_ano_censo', values='qtd_alunos', aggfunc=\"sum\"\n",
    "    ).reset_index().fillna(0)\n",
    "df_serie_temporal.columns.name = None\n",
    "\n",
    "# Adicionando uma coluna com a quantidade de registros no censo para cada turma\n",
    "anos = [str(ano) for ano in range(2007, 2024)]\n",
    "df_serie_temporal['nu_valores'] = df_serie_temporal[anos].apply(lambda row: (row != 0).sum(), axis=1)\n",
    "\n",
    "# Verificando se há interrupção na série temporal\n",
    "def verifica_interrupcao(row):\n",
    "    serie_anos = row[anos]\n",
    "    inicio_atividade = serie_anos[serie_anos != 0].first_valid_index()\n",
    "    fim_atividade = serie_anos[serie_anos != 0].last_valid_index()\n",
    "    return (serie_anos.loc[inicio_atividade:fim_atividade] == 0).any()\n",
    "\n",
    "df_serie_temporal['has_interruption'] = df_serie_temporal.apply(verifica_interrupcao, axis=1)\n",
    "\n",
    "# Salvando o df da série temporal\n",
    "df_serie_temporal.to_csv('<caminho_dados_preprocessados>.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea0f6e-bafe-46ce-8250-9a73e271238d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59601016-49e0-4417-a511-9044bf5d6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transformando para formato longo\n",
    "df_long = pd.melt(df_serie_temporal, id_vars=['co_turma'], var_name='nu_ano_censo', value_name='qt_censo',\n",
    "                  value_vars=[str(year) for year in range(2007, 2023)])\n",
    "df_long = df_long[df_long['qt_censo'] > 0]\n",
    "\n",
    "# Função para calcular estatísticas de um ano específico\n",
    "def calcular_estatisticas(df, ano):\n",
    "    dados_ano = df[df['nu_ano_censo'] == str(ano)]['qt_censo']\n",
    "    return {\n",
    "        'Média ao longo dos anos': dados_ano.mean(),\n",
    "        'Mediana (média entre turmas)': dados_ano.median(),\n",
    "        'Primeiro Quartil (média entre turmas)': dados_ano.quantile(0.25),\n",
    "        'Terceiro Quartil (média entre turmas)': dados_ano.quantile(0.75),\n",
    "    }\n",
    "\n",
    "# Calculando estatísticas para cada ano\n",
    "anos = range(2007, 2023)\n",
    "estatisticas_anuais = {ano: calcular_estatisticas(df_long, ano) for ano in anos}\n",
    "\n",
    "# Convertendo para DataFrame e calculando a média das estatísticas\n",
    "df_estatisticas_anuais = pd.DataFrame(estatisticas_anuais).T\n",
    "estatisticas_media = df_estatisticas_anuais.mean().to_dict()\n",
    "\n",
    "# Calculando o desvio padrão\n",
    "df_serie_temporal['desvio_padrao'] = df_serie_temporal[[str(year) for year in anos]].replace(0, np.nan).std(axis=1, ddof=0)\n",
    "desvio_padrao_medio = df_serie_temporal['desvio_padrao'].mean()\n",
    "\n",
    "# Calculando o mínimo e máximo\n",
    "minimo_geral = df_long['qt_censo'].min()\n",
    "maximo_geral = df_long['qt_censo'].max()\n",
    "\n",
    "# Adicionando os valores ao dicionário de estatísticas médias\n",
    "estatisticas_media.update({\n",
    "    'Desvio Padrão por turma': desvio_padrao_medio,\n",
    "    'Mínimo Geral': df_long['qt_censo'].min(),\n",
    "    'Máximo Geral': df_long['qt_censo'].max(),\n",
    "})\n",
    "\n",
    "# Criando o boxplot para todos os anos\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.ylim(-50, 300)\n",
    "\n",
    "plt.title('Boxplot da Quantidade de Alunos por Ano')\n",
    "plt.xlabel('Ano')\n",
    "plt.ylabel('Quantidade de Alunos')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "sns.boxplot(x='nu_ano_censo', y='qt_censo', data=df_long)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Geração do histograma combinado para todos os anos\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.xlim(0, 250)\n",
    "\n",
    "plt.title('Histograma da Quantidade de Alunos (Todos os Anos)')\n",
    "plt.xlabel('Quantidade de Alunos')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "sns.histplot(data=df_long, x='qt_censo', bins=1000) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5195d834-a766-4d5f-b17d-1de76c1ace91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Determinação de Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8f9a0-47a6-44bd-80d9-18757f68aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_regression_baseline(row, anos):\n",
    "    y = row[anos].values\n",
    "    X = np.array([int(year) for year in anos]).reshape(-1, 1)\n",
    "    mask = y != 0\n",
    "    X, y = X[mask], y[mask]\n",
    "    \n",
    "    if len(y) > 0:\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        return model.predict(np.array([[2023]]))[0]\n",
    "    else:\n",
    "        return np.nan \n",
    "\n",
    "def exponential_smoothing(series, alpha):\n",
    "    result = [series[0]]\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return result\n",
    "\n",
    "def exponential_smoothing_baseline(row, anos, alpha=0.5):\n",
    "    y = row[anos].values\n",
    "    mask = y != 0\n",
    "    y = y[mask]\n",
    "    \n",
    "    if len(y) > 0:\n",
    "        smoothed_values = exponential_smoothing(pd.Series(y), alpha)\n",
    "        return smoothed_values[-1]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Definindo baselines para cada turma (média e repetir o último valor)\n",
    "anos = [str(ano) for ano in range(2007, 2023)]\n",
    "\n",
    "# Calculando a média para os anos entre 2010 e 2022 apenas com valores diferentes de zero\n",
    "df_serie_temporal['baseline_media'] = df_serie_temporal[anos].replace(0, np.NaN).mean(axis=1).round(0)\n",
    "\n",
    "# Repetindo o valor do ano de 2022 como baseline\n",
    "df_serie_temporal['baseline_last_year'] = df_serie_temporal['2022']\n",
    "\n",
    "# Calculando predição através de regressão linear\n",
    "df_serie_temporal['baseline_linear_regression'] = df_serie_temporal.apply(linear_regression_baseline, axis=1, anos=anos).round(0)\n",
    "\n",
    "# Calculando predição através de suavização exponencial\n",
    "df_serie_temporal['baseline_exponential_smoothing'] = df_serie_temporal.apply(exponential_smoothing_baseline, axis=1, anos=anos, alpha=0.5).round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0bf8c8-05d1-4f63-b97d-7edf88fbfb4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac22b6-263d-40dd-9be6-128641b12d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def evaluate_metrics(dataframe, column_base, column_predicted):\n",
    "    # Calculando o Mean Absolute Error (MAE)\n",
    "    mae = np.abs(dataframe[column_base] - dataframe[column_predicted]).mean()\n",
    "    \n",
    "    # Calculando o Standard Deviation (STD)\n",
    "    std = (dataframe[column_base] - dataframe[column_predicted]).std()\n",
    "    \n",
    "    # Calculando o Mean Squared Error (MSE)\n",
    "    mse = ((dataframe[column_base] - dataframe[column_predicted]) ** 2).mean()\n",
    "    \n",
    "    # Calculando o Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Calculando o Mean Absolute Percentage Error (MAPE)\n",
    "    mape = (np.abs((dataframe[column_base] - dataframe[column_predicted]) / dataframe[column_base])).mean() * 100\n",
    "    \n",
    "    # Calculando o R-squared (R²)\n",
    "    ss_res = ((dataframe[column_base] - dataframe[column_predicted]) ** 2).sum()\n",
    "    ss_tot = ((dataframe[column_base] - dataframe[column_base].mean()) ** 2).sum()\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    return {\n",
    "        \"mae\": mae,\n",
    "        \"std\": std,\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"mape\": mape,\n",
    "        \"r_squared\": r_squared\n",
    "    } \n",
    "\n",
    "def apply_wilcoxon_test(df, column1, column2):\n",
    "    stat, p_value = wilcoxon(df[column1], df[column2])\n",
    "    return stat, p_value\n",
    "\n",
    "def test_wilcoxon(df):\n",
    "    results = {\n",
    "        'Baseline': [],\n",
    "        'W-Statistic': [],\n",
    "        'P-Value': []\n",
    "    }\n",
    "    \n",
    "    baselines = ['baseline_media', 'baseline_last_year', 'baseline_linear_regression', 'baseline_exponential_smoothing']\n",
    "    \n",
    "    for baseline in baselines:\n",
    "        w_stat, p_value = apply_wilcoxon_test(df, baseline, 'predicao_kf')\n",
    "        results['Baseline'].append(baseline)\n",
    "        results['W-Statistic'].append(w_stat)\n",
    "        results['P-Value'].append(p_value)\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc365e-d555-4663-885d-9d4564fe647f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Desenvolvimento do Filtro de Kalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8e86d-0715-4ce5-97b7-b172528c82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def run_kalman_filter(data, em_iterations, year_gap):\n",
    "    # Criando DataFrame temporário para pré-processamento\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    temp_df = temp_df[temp_df.cumsum() != 0] # Removendo os zeros iniciais das séries temporais    \n",
    "    temp_df = temp_df.ffill()                # Preenchendo os valores zero no meio da série temporal pelo último valor válido\n",
    "    temp_df = temp_df.dropna()               # Removendo os NaNs resultantes\n",
    "    series = temp_df.values.reshape(-1, 1)   # Extraindo os valores e redimensionando\n",
    "\n",
    "    # Definindo filtro\n",
    "    kalman_filter = KalmanFilter(em_vars=['transition_covariance', 'observation_covariance'])\n",
    "    \n",
    "    # Rodando Filtro de Kalman\n",
    "    kalman_filter = kalman_filter.em(series, n_iter=em_iterations) # Executando o algoritmo EM para estimativa de parâmetros\n",
    "    _, _ = kalman_filter.filter(series)                            # Filtrando os dados\n",
    "    smoothed_state_means, _ = kalman_filter.smooth(series)         # Suavizando os dados\n",
    "\n",
    "    # Predizendo o próximo valor da série\n",
    "    last_smoothed_state = smoothed_state_means[-1]                          # Obtendo o último estado suavizado\n",
    "    next_state = kalman_filter.transition_matrices.dot(last_smoothed_state) # Aplicando a matriz de transição para prever o próximo estado\n",
    "    if year_gap == 2:\n",
    "        next_state = kalman_filter.transition_matrices.dot(next_state)      # Aplicando novamente a matriz de transição para casos em que o gap é de 2 anos\n",
    "    \n",
    "    next_observation = kalman_filter.observation_matrices.dot(next_state)   # Aplicando a matriz de observação para prever a próxima observação\n",
    "\n",
    "    # Retornar o valor previsto\n",
    "    return np.round(next_observation[0]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
